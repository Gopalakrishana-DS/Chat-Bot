{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9c2e617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import json\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "02a2f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dialogs.txt' , sep='\\t' , names=['Question' , 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "375929db",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = data['Question'].tolist()\n",
    "answer_list = data['Answer'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3f06cc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi,</td>\n",
       "      <td>hi how can i help you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>that's a good question. maybe it's not old age.</td>\n",
       "      <td>are you right-handed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>are you right-handed?</td>\n",
       "      <td>yes. all my life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>yes. all my life.</td>\n",
       "      <td>you're wearing out your right hand. stop using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>you're wearing out your right hand. stop using...</td>\n",
       "      <td>but i do all my writing with my right hand.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>but i do all my writing with my right hand.</td>\n",
       "      <td>start typing instead. that way your left hand ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3726 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "0                                                   hi,   \n",
       "1                                hi, how are you doing?   \n",
       "2                         i'm fine. how about yourself?   \n",
       "3                   i'm pretty good. thanks for asking.   \n",
       "4                     no problem. so how have you been?   \n",
       "...                                                 ...   \n",
       "3721    that's a good question. maybe it's not old age.   \n",
       "3722                              are you right-handed?   \n",
       "3723                                  yes. all my life.   \n",
       "3724  you're wearing out your right hand. stop using...   \n",
       "3725        but i do all my writing with my right hand.   \n",
       "\n",
       "                                                 Answer  \n",
       "0                                 hi how can i help you  \n",
       "1                         i'm fine. how about yourself?  \n",
       "2                   i'm pretty good. thanks for asking.  \n",
       "3                     no problem. so how have you been?  \n",
       "4                      i've been great. what about you?  \n",
       "...                                                 ...  \n",
       "3721                              are you right-handed?  \n",
       "3722                                  yes. all my life.  \n",
       "3723  you're wearing out your right hand. stop using...  \n",
       "3724        but i do all my writing with my right hand.  \n",
       "3725  start typing instead. that way your left hand ...  \n",
       "\n",
       "[3726 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2d5bf9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(r'[^\\w\\s]', '' , text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatize_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatize_tokens]\n",
    "    return ' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "af42a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_stopwords(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(r'[^\\w\\s]', '' , text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    lemmatize_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatize_tokens]\n",
    "    return ' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7ccb6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gopal\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "corpus = question_list + answer_list\n",
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
    "X = vectorizer.fit_transform([preprocess(text) for text in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "af7d9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text):\n",
    "    processed_text = preprocess_with_stopwords(text)\n",
    "    print('processed_text:', processed_text)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    similarities = cosine_similarity(vectorized_text, X)\n",
    "    print('similarities:',similarities)\n",
    "    max_similarities = np.max(similarities)\n",
    "    print('max_similarities:',max_similarities)\n",
    "    if max_similarities > 0.6:\n",
    "        high_similarities_questions = [q for q, s in zip(question_list, similarities[0]) if s > 0.6]\n",
    "        print('high_similarities_questions:', high_similarities_questions)\n",
    "        \n",
    "        target_answers = []\n",
    "        for q in high_similarities_questions:\n",
    "            q_index = question_list.index(q)\n",
    "            target_answers.append(answer_list[q_index])\n",
    "        print(target_answers)\n",
    "        \n",
    "        # Use the same vectorizer for both input and high similarity questions\n",
    "        Z = vectorizer.transform([preprocess_with_stopwords(q) for q in high_similarities_questions])\n",
    "        processed_with_stopwords = preprocess_with_stopwords(text)\n",
    "        print('processed_with_stopwords:',processed_with_stopwords)\n",
    "        vectorized_text_with_stopwords = vectorizer.transform([processed_with_stopwords])\n",
    "        final_similarities = cosine_similarity(vectorized_text_with_stopwords, Z)\n",
    "        closet = np.argmax(final_similarities)\n",
    "        return target_answers[closet]\n",
    "    else:\n",
    "        return \"I can't answer this Question\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "008f98e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_text: are you righthand\n",
      "similarities: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "max_similarities: 1.0\n",
      "high_similarities_questions: ['are you right-handed?']\n",
      "['yes. all my life.']\n",
      "processed_with_stopwords: are you righthand\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yes. all my life.'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(\"are you right-handed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f08b9d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/d6/1f/d3b33ca37a147a428581ec8b4834e63cb6f3e7116acf4e2e10f851f45a97/streamlit-1.27.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.27.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Obtaining dependency information for altair<6,>=4.0 from https://files.pythonhosted.org/packages/f2/b4/02a0221bd1da91f6e6acdf0525528db24b4b326a670a9048da474dfe0667/altair-5.1.1-py3-none-any.whl.metadata\n",
      "  Downloading altair-5.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Collecting importlib-metadata<7,>=1.4 (from streamlit)\n",
      "  Obtaining dependency information for importlib-metadata<7,>=1.4 from https://files.pythonhosted.org/packages/cc/37/db7ba97e676af155f5fcb1a35466f446eadc9104e25b83366e8088c9c926/importlib_metadata-6.8.0-py3-none-any.whl.metadata\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (1.26.0)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (2.1.1)\n",
      "Collecting pillow<11,>=7.1.0 (from streamlit)\n",
      "  Obtaining dependency information for pillow<11,>=7.1.0 from https://files.pythonhosted.org/packages/23/ca/7296d769f62266c0f94bf76496bc77114e7a96d2de3d7bcba91d0ba2856f/Pillow-10.0.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading Pillow-10.0.1-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (4.24.3)\n",
      "Collecting pyarrow>=6.0 (from streamlit)\n",
      "  Obtaining dependency information for pyarrow>=6.0 from https://files.pythonhosted.org/packages/f1/04/0c0589aea14748b310489361f732ee813aa9cda0736933d7af8d0225654c/pyarrow-13.0.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading pyarrow-13.0.0-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Obtaining dependency information for rich<14,>=10.14.0 from https://files.pythonhosted.org/packages/c1/d1/23ba6235ed82883bb416f57179d1db2c05f3fb8e5d83c18660f9ab6f09c9/rich-13.5.3-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.5.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
      "  Obtaining dependency information for tenacity<9,>=8.1.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (4.7.1)\n",
      "Collecting tzlocal<6,>=1.1 (from streamlit)\n",
      "  Obtaining dependency information for tzlocal<6,>=1.1 from https://files.pythonhosted.org/packages/84/d2/730a87f0dbf184760394a85088d0d2366a5a8a32bc32ffd869a83f1de854/tzlocal-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading tzlocal-5.0.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit)\n",
      "  Obtaining dependency information for validators<1,>=0.2 from https://files.pythonhosted.org/packages/3a/0c/785d317eea99c3739821718f118c70537639aa43f96bfa1d83a71f68eaf6/validators-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Obtaining dependency information for gitpython!=3.1.19,<4,>=3.0.7 from https://files.pythonhosted.org/packages/8a/7e/20f7e45878b5aed34320fbeeae8f78acc806e7bd708d00b1c6e64b016f5b/GitPython-3.1.37-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.37-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "     ---------------------------------------- 0.0/4.8 MB ? eta -:--:--\n",
      "     ------------- -------------------------- 1.6/4.8 MB 33.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 3.9/4.8 MB 41.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.8/4.8 MB 33.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Collecting watchdog>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-3.0.0-py3-none-win_amd64.whl (82 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7,>=1.4->streamlit)\n",
      "  Obtaining dependency information for zipp>=0.5 from https://files.pythonhosted.org/packages/d9/66/48866fc6b158c81cc2bfecc04c480f105c6040e8b077bc54c634b4a67926/zipp-3.17.0-py3-none-any.whl.metadata\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\gopal\\anaconda3\\envs\\nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading streamlit-1.27.1-py2.py3-none-any.whl (7.5 MB)\n",
      "   ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 45.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.9/7.5 MB 41.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.6/7.5 MB 39.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.3/7.5 MB 39.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.5/7.5 MB 37.1 MB/s eta 0:00:00\n",
      "Using cached altair-5.1.1-py3-none-any.whl (520 kB)\n",
      "Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
      "   ---------------------------------------- 0.0/190.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 190.0/190.0 kB 11.2 MB/s eta 0:00:00\n",
      "Using cached importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading Pillow-10.0.1-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 64.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 32.1 MB/s eta 0:00:00\n",
      "Using cached pyarrow-13.0.0-cp310-cp310-win_amd64.whl (24.3 MB)\n",
      "Downloading rich-13.5.3-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/239.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 239.8/239.8 kB ? eta 0:00:00\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tzlocal-5.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: zipp, watchdog, validators, tzlocal, toolz, toml, tenacity, smmap, pyarrow, pillow, mdurl, blinker, pydeck, markdown-it-py, importlib-metadata, gitdb, rich, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.1.1 blinker-1.6.2 gitdb-4.0.10 gitpython-3.1.37 importlib-metadata-6.8.0 markdown-it-py-3.0.0 mdurl-0.1.2 pillow-10.0.1 pyarrow-13.0.0 pydeck-0.8.1b0 rich-13.5.3 smmap-5.0.1 streamlit-1.27.1 tenacity-8.2.3 toml-0.10.2 toolz-0.12.0 tzlocal-5.0.1 validators-0.22.0 watchdog-3.0.0 zipp-3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31d374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
